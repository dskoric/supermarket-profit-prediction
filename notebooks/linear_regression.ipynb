{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supermarket Profit Prediction\n",
    "\n",
    "In this project we will implement linear regression with one variable to predict profits for a supermarket franchise.\n",
    "\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 - Linear regression with one variable ](#2)\n",
    "  - [ 2.1 Problem Statement](#2.1)\n",
    "  - [ 2.2  Dataset](#2.2)\n",
    "  - [ 2.3 Refresher on linear regression](#2.3)\n",
    "  - [ 2.4  Compute Cost](#2.4)\n",
    "    - [ Exercise 1](#ex01)\n",
    "  - [ 2.5 Gradient descent ](#2.5)\n",
    "    - [ Exercise 2](#ex02)\n",
    "  - [ 2.6 Learning parameters using batch gradient descent ](#2.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Packages \n",
    "\n",
    "First, let's run the cell below to import all the packages that we will need during this assignment.\n",
    "- [numpy](https://www.numpy.org) is the fundamental package for working with matrices in Python.\n",
    "- [matplotlib](https://matplotlib.org) is a famous library to plot graphs in Python.\n",
    "- ``utils.py`` contains helper functions for this assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import copy\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from utils import load_data\n",
    "from linear_regression import compute_cost, compute_gradient, gradient_descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 -  Problem Statement\n",
    "\n",
    "Problem description: Problem description: The CEO of a supermarket chain is considering different cities for opening a new store.\n",
    "\n",
    "- He would like to expand the business to cities that may give higher profits.\n",
    "- The chain already has stores in various cities and we have data for profits and populations from the cities.\n",
    "- We also have data on cities that are candidates for a new restaurant.\n",
    "- For these cities, we have the city population.\n",
    "\n",
    "We will use the data to  identify which cities may potentially give higher profits to the business.\n",
    "\n",
    "## 3 - Dataset\n",
    "\n",
    "We will start by loading the dataset for this task. \n",
    "- The `load_data()` function shown below loads the data into variables `x_train` and `y_train`\n",
    "  - `x_train` is the population of a city\n",
    "  - `y_train` is the profit of a store in that city. A negative value for profit indicates a loss.   \n",
    "  - Both `X_train` and `y_train` are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "x_train, y_train = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the variables\n",
    "Before starting on any task, it is useful to get more familiar with our dataset.  \n",
    "- A good place to start is to just print out each variable and see what it contains.\n",
    "\n",
    "The code below prints the variable `x_train` and the type of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x_train: <class 'numpy.ndarray'>\n",
      "First five elements of x_train are:\n",
      " [6.1101 5.5277 8.5186 7.0032 5.8598]\n"
     ]
    }
   ],
   "source": [
    "# print x_train\n",
    "print(\"Type of x_train:\",type(x_train))\n",
    "print(\"First five elements of x_train are:\\n\", x_train[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_train` is a numpy array that contains decimal values that are all greater than zero.\n",
    "- These values represent the city population times 10,000\n",
    "- For example, 6.1101 means that the population for that city is 61,101\n",
    "  \n",
    "Now, let's print `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of y_train: <class 'numpy.ndarray'>\n",
      "First five elements of y_train are:\n",
      " [17.592   9.1302 13.662  11.854   6.8233]\n"
     ]
    }
   ],
   "source": [
    "# print y_train\n",
    "print(\"Type of y_train:\",type(y_train))\n",
    "print(\"First five elements of y_train are:\\n\", y_train[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, `y_train` is a numpy array that has decimal values, some negative, some positive.\n",
    "- These represent our store's average monthly profits in each city, in units of \\$10,000.\n",
    "  - For example, 17.592 represents \\$175,920 in average monthly profits for that city.\n",
    "  - -2.6807 represents -\\$26,807 in average monthly loss for that city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the dimensions of our variables\n",
    "\n",
    "Another useful way to get familiar with ou data is to view its dimensions.\n",
    "\n",
    "We will print the shape of `x_train` and `y_train` and see how many training examples we have in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is: (97,)\n",
      "The shape of y_train is:  (97,)\n",
      "Number of training examples (m): 97\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of x_train is:', x_train.shape)\n",
    "print ('The shape of y_train is: ', y_train.shape)\n",
    "print ('Number of training examples (m):', len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The city population array has 97 data points, and the monthly average profits also has 97 data points. These are NumPy 1D arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's visualize our data\n",
    "\n",
    "It is often useful to understand the data by visualizing it. \n",
    "- For this dataset, we can use a scatter plot to visualize the data, since it has only two properties to plot (profit and population). \n",
    "- Many other problems that we will encounter in real life have more than two properties (for example, population, average household income, monthly profits, monthly sales).When we have more than two properties, we can still use a scatter plot to see the relationship between each pair of properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot of the data. To change the markers to red \"x\",\n",
    "# we used the 'marker' and 'c' parameters\n",
    "plt.scatter(x_train, y_train, marker='x', c='r') \n",
    "\n",
    "# Set the title\n",
    "plt.title(\"Profits vs. Population per city\")\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Profit in $10,000')\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a linear regression model to fit this data.\n",
    "- With this model, we can then input a new city's population, and have the model estimate our store's potential monthly profits for that city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Refresher on linear regression\n",
    "\n",
    "In this project, we will fit the linear regression parameters $(w,b)$ to our dataset.\n",
    "- The model function for linear regression, which is a function that maps from `x` (city population) to `y` (our store's monthly profit for that city) is represented as \n",
    "    $$f_{w,b}(x) = wx + b$$\n",
    "    \n",
    "\n",
    "- To train a linear regression model, we want to find the best $(w,b)$ parameters that fit our dataset.  \n",
    "\n",
    "    - To compare how one choice of $(w,b)$ is better or worse than another choice, we can evaluate it with a cost function $J(w,b)$\n",
    "      - $J$ is a function of $(w,b)$. That is, the value of the cost $J(w,b)$ depends on the value of $(w,b)$.\n",
    "  \n",
    "    - The choice of $(w,b)$ that fits our data the best is the one that has the smallest cost $J(w,b)$.\n",
    "\n",
    "\n",
    "- To find the values $(w,b)$ that gets the smallest possible cost $J(w,b)$, we can use a method called **gradient descent**. \n",
    "  - With each step of gradient descent, our parameters $(w,b)$ come closer to the optimal values that will achieve the lowest cost $J(w,b)$.\n",
    "  \n",
    "\n",
    "- The trained linear regression model can then take the input feature $x$ (city population) and output a prediction $f_{w,b}(x)$ (predicted monthly profit for a supermarket in that city)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Compute Cost\n",
    "\n",
    "Gradient descent involves repeated steps to adjust the value of our parameter $(w,b)$ to gradually get a smaller and smaller cost $J(w,b)$.\n",
    "- At each step of gradient descent, it will be helpful to monitor our progress by computing the cost $J(w,b)$ as $(w,b)$ gets updated. \n",
    "- In this section, we will implement a function to calculate $J(w,b)$ so that we can check the progress of our gradient descent implementation.\n",
    "\n",
    "#### Cost function\n",
    "For one variable, the cost function for linear regression $J(w,b)$ is defined as\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$$ \n",
    "\n",
    "- We can think of $f_{w,b}(x^{(i)})$ as the model's prediction of our store's profit, as opposed to $y^{(i)}$, which is the actual profit that is recorded in the data.\n",
    "- $m$ is the number of training examples in the dataset\n",
    "\n",
    "#### Model prediction\n",
    "\n",
    "- For linear regression with one variable, the prediction of the model $f_{w,b}$ for an example $x^{(i)}$ is representented as:\n",
    "\n",
    "$$ f_{w,b}(x^{(i)}) = wx^{(i)} + b$$\n",
    "\n",
    "This is the equation for a line, with an intercept $b$ and a slope $w$\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "Now we should complete the `compute_cost()` function below to compute the cost $J(w,b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercise 1\n",
    "\n",
    "Complete the `compute_cost` below to:\n",
    "\n",
    "* Iterate over the training examples, and for each example, compute:\n",
    "    * The prediction of the model for that example \n",
    "    $$\n",
    "    f_{wb}(x^{(i)}) =  wx^{(i)} + b \n",
    "    $$\n",
    "   \n",
    "    * The cost for that example  $$cost^{(i)} =  (f_{wb} - y^{(i)})^2$$\n",
    "    \n",
    "\n",
    "* Return the total cost over all examples\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} cost^{(i)}$$\n",
    "  * Here, $m$ is the number of training examples and $\\sum$ is the summation operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the cost function for linear regression.\n",
    "    \n",
    "    Args:\n",
    "        x (ndarray): Shape (m,) Input to the model (Population of cities) \n",
    "        y (ndarray): Shape (m,) Label (Actual profits for the cities)\n",
    "        w, b (scalar): Parameters of the model\n",
    "    \n",
    "    Returns\n",
    "        total_cost (float): The cost of using w,b as the parameters for linear regression\n",
    "               to fit the data points in x and y\n",
    "    \"\"\"\n",
    "    # number of training examples\n",
    "    m = x.shape[0] \n",
    "    \n",
    "    # We need to return this variable correctly\n",
    "    total_cost = 0\n",
    "    \n",
    "    cost_sum=0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b  # Calculate prediction for current example\n",
    "        cost = (f_wb - y[i]) ** 2  # Calculate squared error for current example\n",
    "        cost_sum += cost  # Accumulate the cost\n",
    "\n",
    "    total_cost = (1 / (2 * m)) * cost_sum\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this by running the following test code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "Cost at initial w: 75.203\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Compute cost with some initial values for paramaters w, b\n",
    "initial_w = 2\n",
    "initial_b = 1\n",
    "\n",
    "cost = compute_cost(x_train, y_train, initial_w, initial_b)\n",
    "print(type(cost))\n",
    "print(f'Cost at initial w: {cost:.3f}')\n",
    "\n",
    "# Public tests\n",
    "from public_tests import *\n",
    "compute_cost_test(compute_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Cost at initial w:<b> 75.203 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Gradient descent \n",
    "\n",
    "In this section, we will implement the gradient for parameters $w, b$ for linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent algorithm is:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \\phantom {0000} b := b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b} \\newline       \\; & \\phantom {0000} w := w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{1}  \\; & \n",
    "\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "where, parameters $w, b$ are both updated simultaniously and where  \n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)} \\tag{3}\n",
    "$$\n",
    "* m is the number of training examples in the dataset\n",
    "\n",
    "    \n",
    "*  $f_{w,b}(x^{(i)})$ is the model's prediction, while $y^{(i)}$, is the target value\n",
    "\n",
    "\n",
    "We will implement a function called `compute_gradient` which calculates $\\frac{\\partial J(w)}{\\partial w}$, $\\frac{\\partial J(w)}{\\partial b}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex02\"></a>\n",
    "### Exercise 2\n",
    "\n",
    "We should complete the `compute_gradient` function to:\n",
    "\n",
    "* Iterate over the training examples, and for each example, compute:\n",
    "    * The prediction of the model for that example \n",
    "    $$\n",
    "    f_{wb}(x^{(i)}) =  wx^{(i)} + b \n",
    "    $$\n",
    "   \n",
    "    * The gradient for the parameters $w, b$ from that example \n",
    "        $$\n",
    "        \\frac{\\partial J(w,b)}{\\partial b}^{(i)}  =  (f_{w,b}(x^{(i)}) - y^{(i)}) \n",
    "        $$\n",
    "        $$\n",
    "        \\frac{\\partial J(w,b)}{\\partial w}^{(i)}  =  (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)} \n",
    "        $$\n",
    "    \n",
    "\n",
    "* Return the total gradient update from all the examples\n",
    "    $$\n",
    "    \\frac{\\partial J(w,b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} \\frac{\\partial J(w,b)}{\\partial b}^{(i)}\n",
    "    $$\n",
    "    \n",
    "    $$\n",
    "    \\frac{\\partial J(w,b)}{\\partial w}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} \\frac{\\partial J(w,b)}{\\partial w}^{(i)} \n",
    "    $$\n",
    "  * Here, $m$ is the number of training examples and $\\sum$ is the summation operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# FUNCTION: compute_gradient\n",
    "def compute_gradient(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      x (ndarray): Shape (m,) Input to the model (Population of cities) \n",
    "      y (ndarray): Shape (m,) Label (Actual profits for the cities)\n",
    "      w, b (scalar): Parameters of the model  \n",
    "    Returns\n",
    "      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\n",
    "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \n",
    "     \"\"\"\n",
    "    \n",
    "    # Number of training examples\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    # We need to return the following variables correctly\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    \n",
    "     # Loop over examples\n",
    "    for i in range(m):  \n",
    "       # Here we get prediction f_wb for the ith example\n",
    "       f_wb = w*x[i] + b\n",
    "\n",
    "       # Here we get the gradient for w from the ith example \n",
    "       dj_dw_i = (f_wb - y[i])*x[i]\n",
    "\n",
    "       # Here we get the gradient for b from the ith example \n",
    "       dj_db_i = (f_wb - y[i])\n",
    "\n",
    "       # Here we update dj_db : In Python, a += 1  is the same as a = a + 1\n",
    "       dj_db += dj_db_i\n",
    "\n",
    "       # The we update dj_dw\n",
    "       dj_dw += dj_dw_i\n",
    "\n",
    "    # Finally we divide both dj_dw and dj_db by m\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "  \n",
    "        \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the cells below to check our implementation of the `compute_gradient` function with two different initializations of the parameters $w$,$b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at initial w, b (zeros): -65.32884974555672 -5.83913505154639\n",
      "Using X with shape (4, 1)\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# This will compute and display gradient with w initialized to zeroes\n",
    "initial_w = 0\n",
    "initial_b = 0\n",
    "\n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, initial_w, initial_b)\n",
    "print('Gradient at initial w, b (zeros):', tmp_dj_dw, tmp_dj_db)\n",
    "\n",
    "compute_gradient_test(compute_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the gradient descent algorithm implemented above on our dataset.\n",
    "\n",
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Gradient at initial , b (zeros)<b></td>\n",
    "    <td> -65.32884975 -5.83913505154639</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at test w, b: -47.41610118114435 -4.007175051546391\n"
     ]
    }
   ],
   "source": [
    "# This will compute and display cost and gradient with non-zero w\n",
    "test_w = 0.2\n",
    "test_b = 0.2\n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, test_w, test_b)\n",
    "\n",
    "print('Gradient at test w, b:', tmp_dj_dw, tmp_dj_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Gradient at test w<b></td>\n",
    "    <td> -47.41610118 -4.007175051546391</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.6\"></a>\n",
    "### 2.6 Learning parameters using batch gradient descent \n",
    "\n",
    "We will now find the optimal parameters of a linear regression model by using batch gradient descent. Batch refers to running all the examples in one iteration.\n",
    "- We don't need to implement anything for this part, just to run the cells below. \n",
    "\n",
    "- A good way to verify that gradient descent is working correctly is to look\n",
    "at the value of $J(w,b)$ and check that it is decreasing with each step. \n",
    "\n",
    "- Assuming we have implemented the gradient and computed the cost correctly and we have an appropriate value for the learning rate alpha, $J(w,b)$ should never increase and should converge to a steady value by the end of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      x :    (ndarray): Shape (m,)\n",
    "      y :    (ndarray): Shape (m,)\n",
    "      w_in, b_in : (scalar) Initial values of parameters of the model\n",
    "      cost_function: function to compute cost\n",
    "      gradient_function: function to compute the gradient\n",
    "      alpha : (float) Learning rate\n",
    "      num_iters : (int) number of iterations to run gradient descent\n",
    "    Returns\n",
    "      w : (ndarray): Shape (1,) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar)                Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of training examples\n",
    "    m = len(x)\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration â€” primarily for graphing later\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_dw, dj_db = gradient_function(x, y, w, b )  \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            cost =  cost_function(x, y, w, b)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            w_history.append(w)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history, w_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the gradient descent algorithm above to learn the parameters for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     6.74   \n",
      "Iteration  150: Cost     5.31   \n",
      "Iteration  300: Cost     4.96   \n",
      "Iteration  450: Cost     4.76   \n",
      "Iteration  600: Cost     4.64   \n",
      "Iteration  750: Cost     4.57   \n",
      "Iteration  900: Cost     4.53   \n",
      "Iteration 1050: Cost     4.51   \n",
      "Iteration 1200: Cost     4.50   \n",
      "Iteration 1350: Cost     4.49   \n",
      "w,b found by gradient descent: 1.166362350335582 -3.63029143940436\n"
     ]
    }
   ],
   "source": [
    "# initialize fitting parameters. We should recall that the shape of w is (n,)\n",
    "initial_w = 0.\n",
    "initial_b = 0.\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "w,b,_,_ = gradient_descent(x_train ,y_train, initial_w, initial_b, \n",
    "                     compute_cost, compute_gradient, alpha, iterations)\n",
    "print(\"w,b found by gradient descent:\", w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b> w, b found by gradient descent<b></td>\n",
    "    <td> 1.16636235 -3.63029143940436</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the final parameters from gradient descent to plot the linear fit. \n",
    "\n",
    "We should recall that we can get the prediction for a single example $f(x^{(i)})= wx^{(i)}+b$. \n",
    "\n",
    "To calculate the predictions on the entire dataset, we can loop through all the training examples and calculate the prediction for each example. This is shown in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "m = x_train.shape[0]\n",
    "predicted = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    predicted[i] = w * x_train[i] + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot the predicted values to see the linear fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Population of City in 10,000s')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the linear fit\n",
    "plt.plot(x_train, predicted, c = \"g\")\n",
    "\n",
    "# Create a scatter plot of the data. \n",
    "plt.scatter(x_train, y_train, marker='*', c='r') \n",
    "\n",
    "# Set the title\n",
    "plt.title(\"Profits vs. Population per city\")\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Profit in $10,000')\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Population of City in 10,000s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final values of $w,b$ can also be used to make predictions on profits. Let's predict what the profit would be in areas of 35,000 and 70,000 people. \n",
    "\n",
    "- The model takes in population of a city in 10,000s as input. \n",
    "\n",
    "- Therefore, 35,000 people can be translated into an input to the model as `np.array([3.5])`\n",
    "\n",
    "- Similarly, 70,000 people can be translated into an input to the model as `np.array([7.])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For population = 35,000, we predict a profit of $4519.77\n",
      "For population = 70,000, we predict a profit of $45342.45\n"
     ]
    }
   ],
   "source": [
    "predict1 = 3.5 * w + b\n",
    "print('For population = 35,000, we predict a profit of $%.2f' % (predict1*10000))\n",
    "\n",
    "predict2 = 7.0 * w + b\n",
    "print('For population = 70,000, we predict a profit of $%.2f' % (predict2*10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b> For population = 35,000, we predict a profit of<b></td>\n",
    "    <td> $4519.77 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td> <b> For population = 70,000, we predict a profit of<b></td>\n",
    "    <td> $45342.45 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
